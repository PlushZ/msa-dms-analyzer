{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "376d9e09-9b1f-4ffe-8b63-2b03e4b231b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import logging\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Text, Float, ForeignKey, inspect, select, delete, func\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship, sessionmaker\n",
    "from sqlalchemy.sql import text\n",
    "from models import GeneURN, Mutation, DMS, DmsRange, MSA, Species, SubstitutionMatrix, IntegratedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcb8de43-9165-42cf-a556-c8a13d4e211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(function_name):\n",
    "    \"\"\"Set up logging to a file with the name of the function in the logs/ folder.\"\"\"\n",
    "    if not os.path.exists('logs'):\n",
    "        os.makedirs('logs')\n",
    "    log_file = os.path.join('logs', f'{function_name}.log')\n",
    "\n",
    "    logging.basicConfig(\n",
    "        filename=log_file,\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63148ff9-3af2-43a0-85d4-f8d36a09c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "engine = create_engine('postgresql://polina_py:polina_py@localhost/dms_msa')\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af04e6c-fcd4-441e-a387-98741e0b2a54",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "#### Datasets inclusion criteria\n",
    "If csv scoreset from MaveDB does not meet all of the following criteria, it's excluded\n",
    "| Inclusion criteria | Reason |\n",
    "| ------------------ | --------------- |\n",
    "| hgvs_pro value is not 'NA', i.e SNP | SNPs represent changes at the DNA level (single nucleotide changes), which do not always lead to a change in the amino acid sequence. Including SNPs that don't result in amino acid changes would introduce noise into your analysis, as these would not be relevant for a comparison with amino acid substitution scores. |\n",
    "| hgvs_pro notation is mave_hgvs | Notations, e.g. full HGVS like 'NP_009225.1:p.Ile1855=' were not parsed, because by default mave_hgvs as a notation of MaveDB is expected |\n",
    "| mutation type = substitution, synonimous, nonsense | Substitution matrices like BLOSUM62 are designed to evaluate the evolutionary likelihood and functional impact of amino acid substitutions. Other types of mutations (e.g., insertions, deletions, frameshifts) alter the protein in different ways and are not comparable to simple substitutions. Including non-substitution mutations in the analysis would lead to mismatched comparisons, as the matrices do not provide relevant scores for these types of mutations. |\n",
    "| single mutant | Double or multiple mutants introduce combinatorial effects that are more complex and not directly comparable to the single substitution scores in BLOSUM62. Including multiple mutants would complicate the analysis and make it difficult to draw clear conclusions about the relationship between DMS scores and BLOSUM62 scores. |\n",
    "| species=Homo sapience | The lack of sufficient data for non-human species in MaveDB, particularly vertebrates, means that any comparative analysis might be statistically underpowered or biased. When more data becomes available, the analysis will be more credible. |\n",
    "| 'score' in dms file is not empty |  |\n",
    "| 'position' in dms file is not empty |  |\n",
    "| unique amino acid mutation | scores for nucleotide mutations that result in the same amino acid change were averaged and only one row in mutation table with the same values of fields: gene_urn_id, species_id,position,wt_residue,variant_residue were left in table. in googlesheet https://docs.google.com/spreadsheets/d/1iyC27xMqadbuQf1HARHYgp1R3rlvpRCZ-LGBippoRSk/edit?gid=1978001822#gid=1978001822 all 19 urns with such duplicates are listed (Examples: 1) c.178_180delinsTAG and c.178_180delinsTAA (in the score set urn:mavedb:00000001-b-2) lead to the same amino acid change, p.Asn60Ter, the scores in these cases are the same, i.e. duplicates, 2) two different scores for D358E in urn:mavedb:00000062-a-1)|\n",
    "| metaAnalyzedByScoreSetUrns in main.json is empty | All scoresets that are a part of a combined meta analysis (which can be identified by parameter metaAnalyzedByScoreSetUrns) are excluded. Only combined metaanalysis scoresets (value of metaAnalyzedByScoreSetUrns) are included to avoid duplication |\n",
    "\n",
    "#### Data pre-processing\n",
    "csv files with dms scores downloaded from MaveDB https://zenodo.org/records/11201737 need to be pre-processed before propagating data from them to msa-dms-db database. \n",
    "1. Data in this notebook has been already processed with workflow in Galaxy https://usegalaxy.eu/u/polina/w/dms-aggregated-parse-hgvs-extract-positions\n",
    "   1. parse hgvs_pro to position, ancestral_residue, variant_residue\n",
    "   2. join parsed table with original table from mavedb by hgvs_pro column\n",
    "\n",
    "3. Convert three-code amino acid to one-code, add columns 'wt_1letter' and 'variant_1letter'\n",
    "\n",
    "#### Data processing\n",
    "1. Populate data to dms_msa PostgrSQL database\n",
    "   1. gene and species are fetched from main.json from zenodo zip-archive and populated urn_gene and species tables\n",
    "   2. then data from preprocessed csv files is populated for existing urn_mavedb in gene_urn table\n",
    "1. Dealing with amino acid mutant duplicates caused by nucleotide mutant records (explained in [Datasets inclusion criteria](#datasets-inclusion-criteria) section)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ed8ecfb-3cc4-405b-a8bd-9664ae4dd21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_from_json(json_path):\n",
    "    # Load the JSON data\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Insert data into the database\n",
    "    for experiment_set in data['experimentSets']:\n",
    "        for experiment in experiment_set['experiments']:\n",
    "            for scoreset in experiment['scoreSets']:\n",
    "                # Check targetGenes and organismName\n",
    "                for target_gene in scoreset['targetGenes']:\n",
    "                    target_sequence = target_gene.get('targetSequence', {})\n",
    "                    taxonomy = target_sequence.get('taxonomy', {})\n",
    "                    organism_name = taxonomy.get('organismName')\n",
    "\n",
    "                    # Proceed only if organismName is 'Homo sapiens'\n",
    "                    if organism_name == 'Homo sapiens':\n",
    "                        urn = scoreset['urn']\n",
    "                        gene_name = target_gene['name']\n",
    "                        target_seq = target_sequence['sequence']\n",
    "\n",
    "                        # Check if urn_mavedb already exists in the database\n",
    "                        existing_entry = session.query(GeneURN).filter_by(urn_mavedb=urn).first()\n",
    "\n",
    "                        if not existing_entry:\n",
    "                            # Create a new gene_urn entry\n",
    "                            gene_urn_entry = GeneURN(\n",
    "                                urn_mavedb=urn,\n",
    "                                gene_name=gene_name,\n",
    "                                target_seq=target_seq\n",
    "                            )\n",
    "\n",
    "                            # Add to the session and commit\n",
    "                            session.add(gene_urn_entry)\n",
    "\n",
    "    # Commit all changes\n",
    "    session.commit()\n",
    "    print(\"Data insertion complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f57707b-390b-4b5d-956d-e1f900c921f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data insertion complete.\n"
     ]
    }
   ],
   "source": [
    "insert_data_from_json('data/main.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d5a504-d821-44c4-ab87-45f4a2e6541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codon table for amino acid mappings\n",
    "codon_table = {\n",
    "    'F': ['TTT', 'TTC'],\n",
    "    'L': ['TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG'],\n",
    "    'I': ['ATT', 'ATC', 'ATA'],\n",
    "    'M': ['ATG'],\n",
    "    'V': ['GTT', 'GTC', 'GTA', 'GTG'],\n",
    "    'S': ['TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC'],\n",
    "    'P': ['CCT', 'CCC', 'CCA', 'CCG'],\n",
    "    'T': ['ACT', 'ACC', 'ACA', 'ACG'],\n",
    "    'A': ['GCT', 'GCC', 'GCA', 'GCG'],\n",
    "    'Y': ['TAT', 'TAC'],\n",
    "    'H': ['CAT', 'CAC'],\n",
    "    'Q': ['CAA', 'CAG'],\n",
    "    'N': ['AAT', 'AAC'],\n",
    "    'K': ['AAA', 'AAG'],\n",
    "    'D': ['GAT', 'GAC'],\n",
    "    'E': ['GAA', 'GAG'],\n",
    "    'C': ['TGT', 'TGC'],\n",
    "    'W': ['TGG'],\n",
    "    'R': ['CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'],\n",
    "    'G': ['GGT', 'GGC', 'GGA', 'GGG'],\n",
    "    '*': ['TAA', 'TAG', 'TGA']\n",
    "}\n",
    "\n",
    "def one_nucleotide_away(codon1, codon2):\n",
    "    \"\"\"Check if two codons are one nucleotide mutation away.\"\"\"\n",
    "    return sum(1 for a, b in zip(codon1, codon2) if a != b) == 1\n",
    "\n",
    "def create_amino_acid_mapping(codon_table):\n",
    "    \"\"\"Create a mapping for amino acids that are one nucleotide away.\"\"\"\n",
    "    amino_acid_mapping = defaultdict(list)\n",
    "    for aa1, codons1 in codon_table.items():\n",
    "        for codon1 in codons1:\n",
    "            for aa2, codons2 in codon_table.items():\n",
    "                if aa1 != aa2:\n",
    "                    for codon2 in codons2:\n",
    "                        if one_nucleotide_away(codon1, codon2):\n",
    "                            amino_acid_mapping[aa1].append(aa2)\n",
    "                            break\n",
    "    return dict(amino_acid_mapping)\n",
    "\n",
    "# Create amino acid mapping based on codon table\n",
    "amino_acid_mapping = create_amino_acid_mapping(codon_table)\n",
    "\n",
    "def process_csv_files(folder_path, session):\n",
    "    # Set up logging for this function\n",
    "    setup_logging('process_csv_files')\n",
    "    \n",
    "    # Query all urn_mavedb values from gene_urn\n",
    "    gene_urns = session.execute(\"SELECT gene_urn_id, urn_mavedb FROM gene_urn\").fetchall()\n",
    "\n",
    "    for gene_urn_id, urn_mavedb in gene_urns:\n",
    "        # Generate the corresponding filename\n",
    "        searched_file_name = f\"csv_{urn_mavedb.replace('urn:mavedb:', 'urn-mavedb-')}.scores.csv\"\n",
    "        file_path = os.path.join(folder_path, searched_file_name)\n",
    "\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            logging.info(f\"File not found: {searched_file_name}\")\n",
    "            continue\n",
    "\n",
    "        with open(file_path, 'r') as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "            for row in csv_reader:\n",
    "                # Skip rows based on conditions\n",
    "                hgvs_pro = row.get('hgvs_pro', '')\n",
    "                if not hgvs_pro or hgvs_pro in ('NA', 'p.=') or hgvs_pro.startswith('p.['):\n",
    "                    continue\n",
    "\n",
    "                if row.get('type') not in ['synonymous', 'substitution']:\n",
    "                    continue\n",
    "\n",
    "                score = row.get('score')\n",
    "                if not score or score == 'NA':\n",
    "                    continue\n",
    "\n",
    "                # Mutation table fields\n",
    "                species_id = 1\n",
    "                position = int(row['start'])\n",
    "                wt_residue = row['wt_1letter']\n",
    "                variant_residue = row['variant_1letter']\n",
    "                \n",
    "                # Calculate edit_distance\n",
    "                edit_distance = 1 if variant_residue in amino_acid_mapping.get(wt_residue, []) else None\n",
    "\n",
    "                # Insert into mutation table\n",
    "                mutation = {\n",
    "                    'gene_urn_id': gene_urn_id,\n",
    "                    'species_id': species_id,\n",
    "                    'position': position,\n",
    "                    'wt_residue': wt_residue,\n",
    "                    'variant_residue': variant_residue,\n",
    "                    'edit_distance': edit_distance\n",
    "                }\n",
    "                session.execute(\"\"\"\n",
    "                    INSERT INTO mutation (gene_urn_id, species_id, position, wt_residue, variant_residue, edit_distance)\n",
    "                    VALUES (:gene_urn_id, :species_id, :position, :wt_residue, :variant_residue, :edit_distance)\n",
    "                    RETURNING mutation_id\n",
    "                \"\"\", mutation)\n",
    "                mutation_id = session.scalar(\"SELECT LASTVAL()\")\n",
    "\n",
    "                # Insert into dms table\n",
    "                dms = {\n",
    "                    'mutation_id': mutation_id,\n",
    "                    'score': float(score)\n",
    "                }\n",
    "                session.execute(\"\"\"\n",
    "                    INSERT INTO dms (mutation_id, score)\n",
    "                    VALUES (:mutation_id, :score)\n",
    "                \"\"\", dms)\n",
    "\n",
    "            session.commit()\n",
    "            logging.info(f\"Processed file: {searched_file_name}\")\n",
    "\n",
    "    print(\"Data insertion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be65553d-51b8-4e17-95ea-ec3d0d84dcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data insertion complete.\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'data/mavedb-all-scores-1letter-part2'\n",
    "process_csv_files(folder_path, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79873b4a-ccb0-43ae-bbdf-7d2ca208b55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: ['substitution_matrix', 'gene_urn', 'mutation', 'species', 'dms', 'msa', 'integrated_data']\n",
      "Schema for table 'substitution_matrix':\n",
      "  Column: amino_acid_x Type: TEXT Nullable: False\n",
      "  Column: amino_acid_y Type: TEXT Nullable: False\n",
      "  Column: BENNER22 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BENNER6 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BENNER74 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLASTN Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLASTP Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLOSUM45 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLOSUM50 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLOSUM62 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLOSUM80 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLOSUM90 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: DAYHOFF Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: FENG Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: GENETIC Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: GONNET1992 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: JOHNSON Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: JONES Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: LEVIN Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: MCLACHLAN Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: MDM78 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: MEGABLAST Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: NUC_4_4 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: PAM250 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: PAM30 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: PAM70 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: RAO Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: RISLER Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: STR Type: DOUBLE_PRECISION Nullable: True\n",
      "Schema for table 'gene_urn':\n",
      "  Column: gene_urn_id Type: INTEGER Nullable: False\n",
      "  Column: urn_mavedb Type: TEXT Nullable: True\n",
      "  Column: gene_name Type: TEXT Nullable: True\n",
      "  Column: target_seq Type: TEXT Nullable: True\n",
      "Schema for table 'mutation':\n",
      "  Column: mutation_id Type: INTEGER Nullable: False\n",
      "  Column: gene_urn_id Type: INTEGER Nullable: True\n",
      "  Column: species_id Type: INTEGER Nullable: True\n",
      "  Column: position Type: INTEGER Nullable: True\n",
      "  Column: wt_residue Type: TEXT Nullable: True\n",
      "  Column: variant_residue Type: TEXT Nullable: True\n",
      "  Column: edit_distance Type: INTEGER Nullable: True\n",
      "Schema for table 'species':\n",
      "  Column: species_id Type: INTEGER Nullable: False\n",
      "  Column: species_name Type: TEXT Nullable: True\n",
      "Schema for table 'dms':\n",
      "  Column: dms_id Type: INTEGER Nullable: False\n",
      "  Column: mutation_id Type: INTEGER Nullable: True\n",
      "  Column: score Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: wt_score Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: min_lof_score Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: max_gof_score Type: DOUBLE_PRECISION Nullable: True\n",
      "Schema for table 'msa':\n",
      "  Column: msa_id Type: INTEGER Nullable: False\n",
      "  Column: mutation_id Type: INTEGER Nullable: True\n",
      "  Column: shannon_entropy Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: jsd Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: phylop Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: phastcons Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: gerp Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: percentage_identity Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: ci Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: variant_percentage_residue Type: DOUBLE_PRECISION Nullable: True\n",
      "Schema for table 'integrated_data':\n",
      "  Column: integrated_data_id Type: INTEGER Nullable: False\n",
      "  Column: mutation_id Type: INTEGER Nullable: True\n",
      "  Column: dms_score Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: shannon_entropy Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: jsd Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: phylop Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: phastcons Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: gerp Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: percentage_identity Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: ci Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: variant_percentage_residue Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BENNER22 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BENNER6 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BENNER74 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLASTN Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLASTP Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLOSUM45 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLOSUM50 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLOSUM62 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLOSUM80 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: BLOSUM90 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: DAYHOFF Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: FENG Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: GENETIC Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: GONNET1992 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: JOHNSON Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: JONES Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: LEVIN Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: MCLACHLAN Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: MDM78 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: MEGABLAST Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: NUC_4_4 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: PAM250 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: PAM30 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: PAM70 Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: RAO Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: RISLER Type: DOUBLE_PRECISION Nullable: True\n",
      "  Column: STR Type: DOUBLE_PRECISION Nullable: True\n",
      "Foreign keys for table 'substitution_matrix':\n",
      "Foreign keys for table 'gene_urn':\n",
      "Foreign keys for table 'mutation':\n",
      "  Foreign key: mutation_gene_urn_id_fkey Columns: ['gene_urn_id'] References: gene_urn(['gene_urn_id'])\n",
      "  Foreign key: mutation_species_id_fkey Columns: ['species_id'] References: species(['species_id'])\n",
      "Foreign keys for table 'species':\n",
      "Foreign keys for table 'dms':\n",
      "  Foreign key: dms_mutation_id_fkey Columns: ['mutation_id'] References: mutation(['mutation_id'])\n",
      "Foreign keys for table 'msa':\n",
      "  Foreign key: msa_mutation_id_fkey Columns: ['mutation_id'] References: mutation(['mutation_id'])\n",
      "Foreign keys for table 'integrated_data':\n",
      "  Foreign key: integrated_data_mutation_id_fkey Columns: ['mutation_id'] References: mutation(['mutation_id'])\n"
     ]
    }
   ],
   "source": [
    "# Create an inspector object\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Get the list of table names\n",
    "tables = inspector.get_table_names()\n",
    "print(\"Tables:\", tables)\n",
    "\n",
    "# Get the schema of a specific table\n",
    "for table in tables:\n",
    "    print(f\"Schema for table '{table}':\")\n",
    "    columns = inspector.get_columns(table)\n",
    "    for column in columns:\n",
    "        print(f\"  Column: {column['name']} Type: {column['type']} Nullable: {column['nullable']}\")\n",
    "\n",
    "# Optionally, you can inspect foreign keys, indexes, etc.\n",
    "for table in tables:\n",
    "    print(f\"Foreign keys for table '{table}':\")\n",
    "    fkeys = inspector.get_foreign_keys(table)\n",
    "    for fkey in fkeys:\n",
    "        print(f\"  Foreign key: {fkey['name']} Columns: {fkey['constrained_columns']} References: {fkey['referred_table']}({fkey['referred_columns']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e6288d6-4297-4205-9347-055ca63f6ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAMP-seq' appeared 6 times under 'urn': urn:mavedb:00000013\n",
      "'VAMP-seq' appeared 4 times under 'urn': urn:mavedb:00000013-a\n",
      "'VAMP-seq' appeared 1 times under 'urn': urn:mavedb:00000013-a-1\n",
      "'VAMP-seq' appeared 4 times under 'urn': urn:mavedb:00000013-b\n",
      "'VAMP-seq' appeared 1 times under 'urn': urn:mavedb:00000013-b-1\n",
      "'VAMP-seq' appeared 3 times under 'urn': urn:mavedb:00000055\n",
      "'VAMP-seq' appeared 2 times under 'urn': urn:mavedb:00000055-a\n",
      "'VAMP-seq' appeared 1 times under 'urn': urn:mavedb:00000055-a-1\n",
      "'VAMP-seq' appeared 2 times under 'urn': urn:mavedb:00000078\n",
      "'VAMP-seq' appeared 2 times under 'urn': urn:mavedb:00000078-b\n",
      "'VAMP-seq' appeared 3 times under 'urn': urn:mavedb:00000095\n",
      "'VAMP-seq' appeared 3 times under 'urn': urn:mavedb:00000095-a\n",
      "'VAMP-seq' appeared 2 times under 'urn': urn:mavedb:00000095-a-1\n",
      "'VAMP-seq' appeared 4 times under 'urn': urn:mavedb:00000095-b\n",
      "'VAMP-seq' appeared 2 times under 'urn': urn:mavedb:00000095-b-1\n",
      "'VAMP-seq' appeared 3 times under 'urn': urn:mavedb:00000101\n",
      "'VAMP-seq' appeared 3 times under 'urn': urn:mavedb:00000101-a\n",
      "'VAMP-seq' appeared 3 times under 'urn': urn:mavedb:00000102-0\n",
      "'VAMP-seq' appeared 1 times under 'urn': urn:mavedb:00000114\n",
      "'VAMP-seq' appeared 2 times under 'urn': urn:mavedb:00000114-a\n",
      "'VAMP-seq' appeared 2 times under 'urn': urn:mavedb:00000657\n",
      "'VAMP-seq' appeared 4 times under 'urn': urn:mavedb:00000657-a\n"
     ]
    }
   ],
   "source": [
    "#function to search score_calc_method through json file\n",
    "def search_json(file_path, search_term):\n",
    "    # Load the JSON data from the file\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Dictionary to hold count of search term for each 'urn'\n",
    "    urn_counts = defaultdict(int)\n",
    "\n",
    "    # Recursive function to search through JSON objects\n",
    "    def recursive_search(obj, parent_urn=None):\n",
    "        if isinstance(obj, dict):\n",
    "            for key, value in obj.items():\n",
    "                if key == 'urn':\n",
    "                    parent_urn = value\n",
    "                if isinstance(value, (dict, list)):\n",
    "                    recursive_search(value, parent_urn)\n",
    "                elif isinstance(value, str) and search_term in value:\n",
    "                    if parent_urn:\n",
    "                        urn_counts[parent_urn] += 1\n",
    "\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                recursive_search(item, parent_urn)\n",
    "\n",
    "    # Start the recursive search\n",
    "    recursive_search(data)\n",
    "\n",
    "    # Print out the result\n",
    "    if urn_counts:\n",
    "        for urn, count in urn_counts.items():\n",
    "            print(f\"'{search_term}' appeared {count} times under 'urn': {urn}\")\n",
    "    else:\n",
    "        print(f\"No occurrences of '{search_term}' found.\")\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    if len(sys.argv) != 3:\n",
    "#        print(\"Usage: python search_json.py <file_path> <search_term>\")\n",
    "#        sys.exit(1)\n",
    "\n",
    "#    file_path = sys.argv[1]\n",
    "#    search_term = sys.argv[2]\n",
    "#    search_json(file_path, search_term)\n",
    "\n",
    "search_json('data/main.json', 'VAMP-seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd2d8fc9-5453-4db2-848e-6f21cbf82337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(session, gene_urn_ids):\n",
    "    try:\n",
    "        start_time = time.time()  # Start time of the script\n",
    "        # Step 1: Find the minimal mutation_id for each unique set of mutation fields\n",
    "        print(\"Step 1: Finding minimal mutation_id for each unique set of mutation fields.\")\n",
    "        min_mutation_ids = session.execute(\n",
    "            text(\"\"\"\n",
    "                SELECT \n",
    "                    gene_urn_id, \n",
    "                    species_id, \n",
    "                    position, \n",
    "                    wt_residue, \n",
    "                    variant_residue,\n",
    "                    MIN(mutation_id) AS min_mutation_id\n",
    "                FROM \n",
    "                    mutation\n",
    "                WHERE \n",
    "                    gene_urn_id IN :gene_urn_ids\n",
    "                GROUP BY \n",
    "                    gene_urn_id, \n",
    "                    species_id, \n",
    "                    position, \n",
    "                    wt_residue, \n",
    "                    variant_residue\n",
    "            \"\"\"),\n",
    "            {'gene_urn_ids': tuple(gene_urn_ids)}\n",
    "        ).fetchall()\n",
    "\n",
    "        min_mutation_ids_set = set(row['min_mutation_id'] for row in min_mutation_ids)\n",
    "        print(f\"Minimal mutation IDs found: {len(min_mutation_ids_set)}\")\n",
    "\n",
    "        # Step 2: Delete rows from the dms table where mutation_id is not the minimum for the duplicates\n",
    "        print(\"Step 2: Deleting rows from the dms table where mutation_id is not the minimum.\")\n",
    "        deleted_dms_result = session.execute(\n",
    "            text(\"\"\"\n",
    "                DELETE FROM dms\n",
    "                WHERE mutation_id NOT IN :min_mutation_ids\n",
    "                AND mutation_id IN (\n",
    "                    SELECT mutation_id \n",
    "                    FROM mutation \n",
    "                    WHERE gene_urn_id IN :gene_urn_ids\n",
    "                )\n",
    "                RETURNING mutation_id\n",
    "            \"\"\"),\n",
    "            {'min_mutation_ids': tuple(min_mutation_ids_set), 'gene_urn_ids': tuple(gene_urn_ids)}\n",
    "        ).fetchall()\n",
    "\n",
    "        deleted_dms_ids = [row['mutation_id'] for row in deleted_dms_result]\n",
    "        print(f\"Number of rows deleted from dms: {len(deleted_dms_ids)}\")\n",
    "\n",
    "        # Step 3: Delete rows from the mutation table with mutation_id values that were deleted from dms\n",
    "        print(\"Step 3: Deleting rows from the mutation table with mutation_id values that were deleted from dms.\")\n",
    "        deleted_mutation_result = session.execute(\n",
    "            text(\"\"\"\n",
    "                DELETE FROM mutation\n",
    "                WHERE mutation_id IN :deleted_dms_ids\n",
    "                AND gene_urn_id IN :gene_urn_ids\n",
    "                RETURNING mutation_id\n",
    "            \"\"\"),\n",
    "            {'deleted_dms_ids': tuple(deleted_dms_ids), 'gene_urn_ids': tuple(gene_urn_ids)}\n",
    "        ).fetchall()\n",
    "\n",
    "        deleted_mutation_ids = [row['mutation_id'] for row in deleted_mutation_result]\n",
    "        print(f\"Number of rows deleted from mutation: {len(deleted_mutation_ids)}\")\n",
    "\n",
    "        session.commit()\n",
    "\n",
    "        end_time = time.time()  # End time of the script\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Total execution time: {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        # Final step: Return lengths of deleted dms and mutation IDs\n",
    "        return len(deleted_dms_ids), len(deleted_mutation_ids)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        session.rollback()\n",
    "        return 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a86c7c1f-4180-4da0-be3b-109e46a70ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Finding minimal mutation_id for each unique set of mutation fields.\n",
      "Minimal mutation IDs found: 2800\n",
      "Step 2: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms: 13899\n",
      "Step 3: Deleting rows from the mutation table with mutation_id values that were deleted from dms.\n",
      "Number of rows deleted from mutation: 13899\n",
      "Total execution time: 6227.89 seconds\n",
      "Final result - Number of rows deleted from dms: 13899\n",
      "Final result - Number of rows deleted from mutation: 13899\n"
     ]
    }
   ],
   "source": [
    "gene_urn_ids = [7]\n",
    "deleted_dms_len, deleted_mutation_len = remove_duplicates(session, gene_urn_ids)\n",
    "print(f\"Final result - Number of rows deleted from dms: {deleted_dms_len}\")\n",
    "print(f\"Final result - Number of rows deleted from mutation: {deleted_mutation_len}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "316adee3-7f1a-46d2-87dc-e38184001bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates2(session, gene_urn_ids):\n",
    "    try:\n",
    "        start_time = time.time()  # Start time of the script\n",
    "\n",
    "        # Step 1: Find the minimal mutation_id for each unique set of mutation fields\n",
    "        print(\"Step 1: Finding minimal mutation_id for each unique set of mutation fields.\")\n",
    "        min_mutation_ids = session.execute(\n",
    "            text(\"\"\"\n",
    "                SELECT \n",
    "                    MIN(mutation_id) AS min_mutation_id\n",
    "                FROM \n",
    "                    mutation\n",
    "                WHERE \n",
    "                    gene_urn_id IN :gene_urn_ids\n",
    "                GROUP BY \n",
    "                    gene_urn_id, \n",
    "                    species_id, \n",
    "                    position, \n",
    "                    wt_residue, \n",
    "                    variant_residue\n",
    "            \"\"\"),\n",
    "            {'gene_urn_ids': tuple(gene_urn_ids)}\n",
    "        ).fetchall()\n",
    "\n",
    "        min_mutation_ids_set = set(row['min_mutation_id'] for row in min_mutation_ids)\n",
    "        print(f\"Minimal mutation IDs found in gene_urn_ids {gene_urn_ids}: {len(min_mutation_ids_set)}\")\n",
    "\n",
    "        # Step 2: Delete rows from the dms table where mutation_id is not the minimum for the duplicates\n",
    "        print(\"Step 2: Deleting rows from the dms table where mutation_id is not the minimum.\")\n",
    "        deleted_dms_result = session.execute(\n",
    "            text(\"\"\"\n",
    "                DELETE FROM dms\n",
    "                WHERE mutation_id NOT IN :min_mutation_ids\n",
    "                AND mutation_id IN (\n",
    "                    SELECT mutation_id \n",
    "                    FROM mutation \n",
    "                    WHERE gene_urn_id IN :gene_urn_ids\n",
    "                )\n",
    "            \"\"\"),\n",
    "            {'min_mutation_ids': tuple(min_mutation_ids_set), 'gene_urn_ids': tuple(gene_urn_ids)}\n",
    "        )\n",
    "        print(f\"Number of rows deleted from dms in gene_urn_ids {gene_urn_ids}: {deleted_dms_result.rowcount}\")\n",
    "\n",
    "        # Step 3: Delete rows from the mutation table with mutation_id values that are not minimal\n",
    "        print(\"Step 3: Deleting rows from the mutation table where mutation_id is not the minimum.\")\n",
    "        deleted_mutation_result = session.execute(\n",
    "            text(\"\"\"\n",
    "                DELETE FROM mutation\n",
    "                WHERE mutation_id NOT IN :min_mutation_ids\n",
    "                AND gene_urn_id IN :gene_urn_ids\n",
    "            \"\"\"),\n",
    "            {'min_mutation_ids': tuple(min_mutation_ids_set), 'gene_urn_ids': tuple(gene_urn_ids)}\n",
    "        )\n",
    "        print(f\"Number of rows deleted from mutation in gene_urn_ids {gene_urn_ids}: {deleted_mutation_result.rowcount}\")\n",
    "\n",
    "        session.commit()\n",
    "\n",
    "        end_time = time.time()  # End time of the script\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Total execution time for gene_urn_ids {gene_urn_ids}: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "        # Final step: Return lengths of deleted dms and mutation IDs\n",
    "        return deleted_dms_result.rowcount, deleted_mutation_result.rowcount\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        session.rollback()\n",
    "        return 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7ad7d5d-40c9-41dd-afef-1a1089aca2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Finding minimal mutation_id for each unique set of mutation fields.\n",
      "Minimal mutation IDs found: 3174\n",
      "Step 2: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms: 19458\n",
      "Step 3: Deleting rows from the mutation table where mutation_id is not the minimum.\n",
      "Number of rows deleted from mutation: 19458\n",
      "Total execution time: 3580.31 seconds\n",
      "Final result - Number of rows deleted from dms: 19458\n",
      "Final result - Number of rows deleted from mutation: 19458\n"
     ]
    }
   ],
   "source": [
    "gene_urn_ids = [3]\n",
    "deleted_dms_len, deleted_mutation_len = remove_duplicates2(session, gene_urn_ids)\n",
    "print(f\"Final result - Number of rows deleted from dms: {deleted_dms_len}\")\n",
    "print(f\"Final result - Number of rows deleted from mutation: {deleted_mutation_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87a0a23b-ea2b-4f65-9875-f46996275178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Finding minimal mutation_id for each unique set of mutation fields.\n",
      "Minimal mutation IDs found in gene_urn_ids [4]: 3176\n",
      "Step 2: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms in gene_urn_ids [4]: 22426\n",
      "Step 3: Deleting rows from the mutation table where mutation_id is not the minimum.\n",
      "Number of rows deleted from mutation in gene_urn_ids [4]: 22426\n",
      "Total execution time for gene_urn_ids [4]: 4892.25 seconds\n",
      "Step 1: Finding minimal mutation_id for each unique set of mutation fields.\n",
      "Minimal mutation IDs found in gene_urn_ids [10]: 4584\n",
      "Step 2: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms in gene_urn_ids [10]: 21614\n",
      "Step 3: Deleting rows from the mutation table where mutation_id is not the minimum.\n",
      "Number of rows deleted from mutation in gene_urn_ids [10]: 21614\n",
      "Total execution time for gene_urn_ids [10]: 4781.32 seconds\n",
      "Step 1: Finding minimal mutation_id for each unique set of mutation fields.\n",
      "Minimal mutation IDs found in gene_urn_ids [17]: 7935\n",
      "Step 2: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms in gene_urn_ids [17]: 13161\n",
      "Step 3: Deleting rows from the mutation table where mutation_id is not the minimum.\n",
      "Number of rows deleted from mutation in gene_urn_ids [17]: 13161\n",
      "Total execution time for gene_urn_ids [17]: 2547.13 seconds\n",
      "Step 1: Finding minimal mutation_id for each unique set of mutation fields.\n",
      "Minimal mutation IDs found in gene_urn_ids [21]: 7653\n",
      "Step 2: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms in gene_urn_ids [21]: 11563\n",
      "Step 3: Deleting rows from the mutation table where mutation_id is not the minimum.\n",
      "Number of rows deleted from mutation in gene_urn_ids [21]: 11563\n",
      "Total execution time for gene_urn_ids [21]: 2156.59 seconds\n"
     ]
    }
   ],
   "source": [
    "deleted_dms_len, deleted_mutation_len = remove_duplicates2(session, [4])\n",
    "deleted_dms_len, deleted_mutation_len = remove_duplicates2(session, [10])\n",
    "deleted_dms_len, deleted_mutation_len = remove_duplicates2(session, [17])\n",
    "deleted_dms_len, deleted_mutation_len = remove_duplicates2(session, [21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed376bc1-bd0f-4c80-bee4-ed0cc976a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_and_remove_duplicates(session, gene_urn_ids):\n",
    "    try:\n",
    "        start_time = time.time()  # Start time of the script\n",
    "\n",
    "        # Step 1: Calculate the average score for each unique set of mutation fields for all gene_urn_ids\n",
    "        print(\"Step 1: Calculating the average score for each unique set of mutation fields.\")\n",
    "        avg_scores = session.execute(\n",
    "            text(\"\"\"\n",
    "                SELECT\n",
    "                    MIN(m.mutation_id) AS min_mutation_id,\n",
    "                    AVG(d.score) AS avg_score\n",
    "                FROM \n",
    "                    mutation m\n",
    "                JOIN \n",
    "                    dms d ON m.mutation_id = d.mutation_id\n",
    "                WHERE \n",
    "                    m.gene_urn_id IN :gene_urn_ids\n",
    "                GROUP BY \n",
    "                    m.gene_urn_id, \n",
    "                    m.species_id, \n",
    "                    m.position, \n",
    "                    m.wt_residue, \n",
    "                    m.variant_residue\n",
    "            \"\"\"),\n",
    "            {'gene_urn_ids': tuple(gene_urn_ids)}\n",
    "        ).fetchall()\n",
    "\n",
    "        min_mutation_ids_set = set(row['min_mutation_id'] for row in avg_scores)\n",
    "        print(f\"Number of unique sets with average scores calculated: {len(min_mutation_ids_set)}\")\n",
    "\n",
    "        # Step 2: Update the dms table with the average score for the row with the minimum mutation_id\n",
    "        print(\"Step 2: Updating the dms table with the average score for the minimum mutation_id.\")\n",
    "        for row in avg_scores:\n",
    "            session.execute(\n",
    "                text(\"\"\"\n",
    "                    UPDATE dms\n",
    "                    SET score = :avg_score\n",
    "                    WHERE mutation_id = :min_mutation_id\n",
    "                \"\"\"),\n",
    "                {'avg_score': row['avg_score'], 'min_mutation_id': row['min_mutation_id']}\n",
    "            )\n",
    "        \n",
    "        session.flush()  # Flush to ensure updates are applied\n",
    "\n",
    "        # Step 3: Delete rows from the dms table where mutation_id is greater than the minimum mutation_id\n",
    "        print(\"Step 3: Deleting rows from the dms table where mutation_id is not the minimum.\")\n",
    "        deleted_dms_result = session.execute(\n",
    "            text(\"\"\"\n",
    "                DELETE FROM dms\n",
    "                WHERE mutation_id NOT IN :min_mutation_ids\n",
    "                AND mutation_id IN (\n",
    "                    SELECT mutation_id \n",
    "                    FROM mutation \n",
    "                    WHERE gene_urn_id IN :gene_urn_ids\n",
    "                )\n",
    "            \"\"\"),\n",
    "            {'min_mutation_ids': tuple(min_mutation_ids_set), 'gene_urn_ids': tuple(gene_urn_ids)}\n",
    "        )\n",
    "\n",
    "        print(f\"Number of rows deleted from dms: {deleted_dms_result.rowcount}\")\n",
    "\n",
    "        # Step 4: Delete rows from the mutation table with mutation_id values that were deleted from dms\n",
    "        print(\"Step 4: Deleting rows from the mutation table where mutation_id values were deleted from dms.\")\n",
    "        deleted_mutation_result = session.execute(\n",
    "            text(\"\"\"\n",
    "                DELETE FROM mutation\n",
    "                WHERE mutation_id NOT IN :min_mutation_ids\n",
    "                AND gene_urn_id IN :gene_urn_ids\n",
    "            \"\"\"),\n",
    "            {'min_mutation_ids': tuple(min_mutation_ids_set), 'gene_urn_ids': tuple(gene_urn_ids)}\n",
    "        )\n",
    "\n",
    "        print(f\"Number of rows deleted from mutation: {deleted_mutation_result.rowcount}\")\n",
    "\n",
    "        session.commit()\n",
    "\n",
    "        end_time = time.time()  # End time of the script\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Total execution time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "        # Final step: Return lengths of deleted dms and mutation IDs\n",
    "        return deleted_dms_result.rowcount, deleted_mutation_result.rowcount\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        session.rollback()\n",
    "        return 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6ba580d-6de9-46de-9206-7794e071ab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Calculating the average score for each unique set of mutation fields.\n",
      "Number of unique sets with average scores calculated: 407\n",
      "Step 2: Updating the dms table with the average score for the minimum mutation_id.\n",
      "Step 3: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms: 463\n",
      "Step 4: Deleting rows from the mutation table where mutation_id values were deleted from dms.\n",
      "Number of rows deleted from mutation: 463\n",
      "Total execution time: 82.57 seconds\n"
     ]
    }
   ],
   "source": [
    "deleted_dms_len, deleted_mutation_len = average_and_remove_duplicates(session, [528])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4038b89e-e1a3-4962-a00e-e2c345fafec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Calculating the average score for each unique set of mutation fields.\n",
      "Number of unique sets with average scores calculated: 412\n",
      "Step 2: Updating the dms table with the average score for the minimum mutation_id.\n",
      "Step 3: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms: 465\n",
      "Step 4: Deleting rows from the mutation table where mutation_id values were deleted from dms.\n",
      "Number of rows deleted from mutation: 465\n",
      "Total execution time: 93.09 seconds\n",
      "Step 1: Calculating the average score for each unique set of mutation fields.\n",
      "Number of unique sets with average scores calculated: 412\n",
      "Step 2: Updating the dms table with the average score for the minimum mutation_id.\n",
      "Step 3: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms: 472\n",
      "Step 4: Deleting rows from the mutation table where mutation_id values were deleted from dms.\n",
      "Number of rows deleted from mutation: 472\n",
      "Total execution time: 192.93 seconds\n",
      "Step 1: Calculating the average score for each unique set of mutation fields.\n",
      "Number of unique sets with average scores calculated: 412\n",
      "Step 2: Updating the dms table with the average score for the minimum mutation_id.\n",
      "Step 3: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms: 472\n",
      "Step 4: Deleting rows from the mutation table where mutation_id values were deleted from dms.\n",
      "Number of rows deleted from mutation: 472\n",
      "Total execution time: 172.39 seconds\n",
      "Step 1: Calculating the average score for each unique set of mutation fields.\n",
      "Number of unique sets with average scores calculated: 1197\n",
      "Step 2: Updating the dms table with the average score for the minimum mutation_id.\n",
      "Step 3: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms: 320\n",
      "Step 4: Deleting rows from the mutation table where mutation_id values were deleted from dms.\n",
      "Number of rows deleted from mutation: 320\n",
      "Total execution time: 298.91 seconds\n",
      "Step 1: Calculating the average score for each unique set of mutation fields.\n",
      "Number of unique sets with average scores calculated: 1326\n",
      "Step 2: Updating the dms table with the average score for the minimum mutation_id.\n",
      "Step 3: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms: 370\n",
      "Step 4: Deleting rows from the mutation table where mutation_id values were deleted from dms.\n",
      "Number of rows deleted from mutation: 370\n",
      "Total execution time: 358.10 seconds\n",
      "Step 1: Calculating the average score for each unique set of mutation fields.\n",
      "Number of unique sets with average scores calculated: 591\n",
      "Step 2: Updating the dms table with the average score for the minimum mutation_id.\n",
      "Step 3: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms: 5776\n",
      "Step 4: Deleting rows from the mutation table where mutation_id values were deleted from dms.\n",
      "Number of rows deleted from mutation: 5776\n",
      "Total execution time: 1150.81 seconds\n",
      "Step 1: Calculating the average score for each unique set of mutation fields.\n",
      "Number of unique sets with average scores calculated: 591\n",
      "Step 2: Updating the dms table with the average score for the minimum mutation_id.\n",
      "Step 3: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms: 5849\n",
      "Step 4: Deleting rows from the mutation table where mutation_id values were deleted from dms.\n",
      "Number of rows deleted from mutation: 5849\n",
      "Total execution time: 1351.37 seconds\n",
      "Step 1: Calculating the average score for each unique set of mutation fields.\n",
      "Number of unique sets with average scores calculated: 3341\n",
      "Step 2: Updating the dms table with the average score for the minimum mutation_id.\n",
      "Step 3: Deleting rows from the dms table where mutation_id is not the minimum.\n",
      "Number of rows deleted from dms: 8394\n",
      "Step 4: Deleting rows from the mutation table where mutation_id values were deleted from dms.\n",
      "Number of rows deleted from mutation: 8394\n",
      "Total execution time: 2423.67 seconds\n"
     ]
    }
   ],
   "source": [
    "deleted_dms_len, deleted_mutation_len = average_and_remove_duplicates(session, [527])\n",
    "deleted_dms_len, deleted_mutation_len = average_and_remove_duplicates(session, [526])\n",
    "deleted_dms_len, deleted_mutation_len = average_and_remove_duplicates(session, [525])\n",
    "deleted_dms_len, deleted_mutation_len = average_and_remove_duplicates(session, [15])\n",
    "deleted_dms_len, deleted_mutation_len = average_and_remove_duplicates(session, [13])\n",
    "deleted_dms_len, deleted_mutation_len = average_and_remove_duplicates(session, [63])\n",
    "deleted_dms_len, deleted_mutation_len = average_and_remove_duplicates(session, [64])\n",
    "deleted_dms_len, deleted_mutation_len = average_and_remove_duplicates(session, [109])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5120fb-3cfe-4f50-ae3f-fa79ac4018ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick-check-availability-syn-nonsense-vars-in-sets\n",
    "def fetch_all_gene_urns():\n",
    "    # Query to get all gene_urn.urn_mavedb\n",
    "    result = session.execute(\n",
    "        text(\"SELECT urn_mavedb FROM gene_urn\")\n",
    "    )\n",
    "    return result.fetchall()\n",
    "\n",
    "def process_urn(urn_mavedb, csv_folder_path):\n",
    "    # Step 1: Create filename\n",
    "    urn_filename = 'csv_' + urn_mavedb.replace('urn:mavedb:', 'urn-mavedb-') + '.scores.csv'\n",
    "    urn_filepath = os.path.join(csv_folder_path, urn_filename)\n",
    "\n",
    "    synonymous_score = 'not found'\n",
    "    nonsense_score = 'not found'\n",
    "\n",
    "    # Check if file exists\n",
    "    if os.path.isfile(urn_filepath):\n",
    "        # Open CSV file and search for 'synonymous' in 'type' column and '*' in 'variant_1letter' column\n",
    "        with open(urn_filepath, mode='r') as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file)\n",
    "            for row in csv_reader:\n",
    "                # Step 2: Search for 'synonymous' in 'type' column\n",
    "                if row.get('type') == 'synonymous' and synonymous_score == 'not found':\n",
    "                    synonymous_score = row.get('score', 'not found')\n",
    "                # Step 3: Search for '*' in 'variant_1letter' column\n",
    "                if row.get('variant_1letter') == '*' and nonsense_score == 'not found':\n",
    "                    nonsense_score = row.get('score', 'not found')\n",
    "                # If both scores are found, exit loop\n",
    "                if synonymous_score != 'not found' and nonsense_score != 'not found':\n",
    "                    break\n",
    "    else:\n",
    "        print(f\"File {urn_filepath} not found.\")\n",
    "\n",
    "    return synonymous_score, nonsense_score\n",
    "\n",
    "def generate_report(csv_folder_path, report_file_path):\n",
    "    # Fetch all urn_mavedb values\n",
    "    gene_urns = fetch_all_gene_urns()\n",
    "\n",
    "    # Open report file for writing\n",
    "    with open(report_file_path, mode='w', newline='') as report_file:\n",
    "        fieldnames = ['urn', 'synonymous_score', 'nonsense_score']\n",
    "        writer = csv.DictWriter(report_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Process each urn and write the results to the report\n",
    "        for gene_urn in gene_urns:\n",
    "            urn_mavedb = gene_urn['urn_mavedb']\n",
    "            #print(f\"Processing {urn_mavedb}...\")\n",
    "\n",
    "            # Process the urn and get the synonymous and nonsense scores\n",
    "            synonymous_score, nonsense_score = process_urn(urn_mavedb, csv_folder_path)\n",
    "\n",
    "            # Write the results to the report\n",
    "            writer.writerow({\n",
    "                'urn': urn_mavedb,\n",
    "                'synonymous_score': synonymous_score,\n",
    "                'nonsense_score': nonsense_score\n",
    "            })\n",
    "\n",
    "    print(f\"Report generated: {report_file_path}\")\n",
    "\n",
    "csv_folder_path = 'data/mavedb-scores-postgres/mavedb-all-scores-1letter'\n",
    "report_file_path = 'data/mavedb-scores-postgres/report-synonymous-nonsense.csv'\n",
    "generate_report(csv_folder_path, report_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6ee2802-ca53-4f57-b697-b673e347b481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 1054\n",
      "Rows where both 'synonymous_score' and 'nonsense_score' are 'not found' or empty: 151\n",
      "Rows where only 'synonymous_score' is 'not found' or empty: 51\n",
      "Rows where only 'nonsense_score' is 'not found' or empty: 349\n"
     ]
    }
   ],
   "source": [
    "def analyze_report(report_file_path):\n",
    "    # Initialize counters\n",
    "    total_rows = 0\n",
    "    both_not_found_count = 0\n",
    "    only_synonymous_not_found_count = 0\n",
    "    only_nonsense_not_found_count = 0\n",
    "\n",
    "    # Open the report CSV file for reading\n",
    "    with open(report_file_path, mode='r') as report_file:\n",
    "        reader = csv.DictReader(report_file)\n",
    "\n",
    "        # Iterate over each row in the report\n",
    "        for row in reader:\n",
    "            total_rows += 1\n",
    "            synonymous_score = row.get('synonymous_score', '').strip()\n",
    "            nonsense_score = row.get('nonsense_score', '').strip()\n",
    "\n",
    "            # Check the conditions for the scores being 'not found' or empty\n",
    "            if (synonymous_score == 'not found' or synonymous_score == '') and \\\n",
    "               (nonsense_score == 'not found' or nonsense_score == ''):\n",
    "                both_not_found_count += 1\n",
    "            elif synonymous_score == 'not found' or synonymous_score == '':\n",
    "                only_synonymous_not_found_count += 1\n",
    "            elif nonsense_score == 'not found' or nonsense_score == '':\n",
    "                only_nonsense_not_found_count += 1\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Total number of rows: {total_rows}\")\n",
    "    print(f\"Rows where both 'synonymous_score' and 'nonsense_score' are 'not found' or empty: {both_not_found_count}\")\n",
    "    print(f\"Rows where only 'synonymous_score' is 'not found' or empty: {only_synonymous_not_found_count}\")\n",
    "    print(f\"Rows where only 'nonsense_score' is 'not found' or empty: {only_nonsense_not_found_count}\")\n",
    "\n",
    "\n",
    "analyze_report('data/mavedb-scores-postgres/report-synonymous-nonsense.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b312f9bc-c8d3-438e-8de8-ad023b8640b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a report \n",
    "#to distinguish all urns with metaAnalyzedBy not empty parameter in json\n",
    "#and if there are records for them in mutation table\n",
    "with open('data/main.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Inspect the loaded data structure\n",
    "print(f\"Data type: {type(data)}\")  # Should print <class 'dict'>\n",
    "print(data.keys())  # This will show the keys in the dictionary, helping you navigate\n",
    "\n",
    "# Step 3: Access the list of experiments (adjust this according to your actual JSON structure)\n",
    "experiment_sets = data.get('experimentSets', [])\n",
    "\n",
    "# Initialize an empty list to store report rows\n",
    "report_data = []\n",
    "\n",
    "for experiment_set in experiment_sets:\n",
    "    # Ensure experiment_set is a dictionary\n",
    "    if isinstance(experiment_set, dict):\n",
    "        experiments = experiment_set.get('experiments', [])\n",
    "        \n",
    "        for experiment in experiments:\n",
    "            if isinstance(experiment, dict):\n",
    "                score_sets = experiment.get('scoreSets', [])\n",
    "                \n",
    "                for score_set in score_sets:\n",
    "                    if isinstance(score_set, dict):\n",
    "                        urn = score_set.get('urn', None)\n",
    "                        metaAnalyzedByScoreSetUrns = score_set.get('metaAnalyzedByScoreSetUrns', [])\n",
    "                        \n",
    "                        # Check if metaAnalyzedByScoreSetUrns is not empty\n",
    "                        meta_analyzed_col = 'yes' if metaAnalyzedByScoreSetUrns else 'no'\n",
    "                        \n",
    "                        # Initialize columns for the report\n",
    "                        is_in_gene_urn_col = 'no'\n",
    "                        mutation_records_found_col = 'no'\n",
    "\n",
    "                        if urn:\n",
    "                            # Step 5: Query gene_urn table to check if urn exists\n",
    "                            gene_urn_entry = session.query(GeneURN).filter_by(urn_mavedb=urn).first()\n",
    "\n",
    "                            if gene_urn_entry:\n",
    "                                is_in_gene_urn_col = 'yes'\n",
    "                                gene_urn_id = gene_urn_entry.gene_urn_id\n",
    "\n",
    "                                # Step 6: Query mutation table to check for records with this gene_urn_id\n",
    "                                mutation_count = session.query(Mutation).filter_by(gene_urn_id=gene_urn_id).count()\n",
    "\n",
    "                                if mutation_count > 0:\n",
    "                                    mutation_records_found_col = 'yes'\n",
    "\n",
    "                        # Step 7: Append the results to the report\n",
    "                        report_data.append({\n",
    "                            'urn': urn,\n",
    "                            'gene_urn_id': gene_urn_id,                            \n",
    "                            'json: metaAnalyzedByScoreSetUrns not empty': meta_analyzed_col,\n",
    "                            'db: is in gene_urn table': is_in_gene_urn_col,\n",
    "                            'db: mutation records found': mutation_records_found_col\n",
    "                        })\n",
    "                    else:\n",
    "                        print(f\"Skipping non-dictionary score set: {score_set}\")\n",
    "            else:\n",
    "                print(f\"Skipping non-dictionary experiment: {experiment}\")\n",
    "    else:\n",
    "        print(f\"Skipping non-dictionary experiment set: {experiment_set}\")\n",
    "\n",
    "# Step 8: Convert to DataFrame for easier export\n",
    "report_df = pd.DataFrame(report_data)\n",
    "\n",
    "# Step 9: Export to CSV\n",
    "report_df.to_csv('data/reports/report-metaanalysis-duplicates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dddaa8c-bb6e-4b63-94b7-722a4a40bf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196889 records deleted from dms table.\n"
     ]
    }
   ],
   "source": [
    "#delete these duplicates that have metaAnalyzedBy not empty and more than 0 records in mutaiton table\n",
    "#gene_urn_ids are taked from report-metaanalysis-duplicates.csv file created by previous script\n",
    "\n",
    "# Step 2: List of gene_urn_ids to delete\n",
    "gene_urn_ids_to_delete = [\n",
    "    25, 102, 103, 196, 245, 246, 247, 248, 250, 251, 253, 254, 256, 257, 259, \n",
    "    260, 263, 264, 265, 266, 268, 269, 272, 273, 275, 276, 277, 278, 280, 281, \n",
    "    284, 285, 287, 288, 289, 290, 292, 293, 296, 297, 299, 300, 302, 303, 305, \n",
    "    306, 307, 308, 310, 311, 314, 315, 316, 317, 320, 321, 322, 323, 326, 327, \n",
    "    329, 330, 331, 332, 335, 336, 338, 339, 341, 342, 343, 344, 347, 348, 349, \n",
    "    350, 353, 354, 356, 357, 358, 359, 362, 363, 365, 366, 367, 368, 370, 371, \n",
    "    373, 374, 377, 378, 379, 380, 382, 383, 386, 387, 389, 390, 392, 393, 395, \n",
    "    396, 398, 399, 400, 401, 404, 405, 407, 408, 410, 411, 412, 413, 416, 417, \n",
    "    419, 420, 421, 422, 425, 427, 428, 431, 432, 433, 434, 437, 438, 439, \n",
    "    440, 443, 444, 446, 447, 449, 450, 452, 453, 455, 456, 458, 459, 460, 461, \n",
    "    463, 464, 467, 468, 470, 471, 472, 473, 475, 476, 479, 480, 481, 482, 485, \n",
    "    486, 488, 489, 491, 492, 493, 494, 497, 498, 499, 500, 503, 504\n",
    "]\n",
    "\n",
    "gene_urn_ids_to_delete_1 =[424]\n",
    "\n",
    "\n",
    "# Step 3: Find all mutation_ids in mutation table where gene_urn_id is in the list\n",
    "mutation_ids_to_delete = session.query(Mutation.mutation_id).filter(Mutation.gene_urn_id.in_(gene_urn_ids_to_delete)).all()\n",
    "\n",
    "# Extract mutation_ids as a flat list\n",
    "mutation_ids_to_delete = [m[0] for m in mutation_ids_to_delete]\n",
    "\n",
    "# Step 4: Delete records from dms table where mutation_id matches\n",
    "if mutation_ids_to_delete:\n",
    "    dms_delete_query = session.query(DMS).filter(DMS.mutation_id.in_(mutation_ids_to_delete)).delete(synchronize_session=False)\n",
    "    print(f\"{dms_delete_query} records deleted from dms table.\")\n",
    "\n",
    "\n",
    "# Step 5: Delete records from the mutation table\n",
    "delete_query = session.query(Mutation).filter(Mutation.gene_urn_id.in_(gene_urn_ids_to_delete)).delete(synchronize_session=False)\n",
    "\n",
    "# Step 6: Commit the changes\n",
    "session.commit()\n",
    "\n",
    "# Step 7: Print confirmation\n",
    "print(f\"{delete_query} records deleted from mutation table.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d417121-02ff-4980-bea6-f6626e0a4f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: name 'Dms' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Step 2: List of gene_urn_ids to delete\n",
    "gene_urn_ids_to_delete_1 = [424]  # Example list, use your full list here\n",
    "\n",
    "try:\n",
    "    # Step 3: Find all mutation_ids in mutation table where gene_urn_id is in the list\n",
    "    mutation_ids_to_delete = session.query(Mutation.mutation_id).filter(Mutation.gene_urn_id.in_(gene_urn_ids_to_delete_1)).all()\n",
    "\n",
    "    # Extract mutation_ids as a flat list\n",
    "    mutation_ids_to_delete = [m[0] for m in mutation_ids_to_delete]\n",
    "\n",
    "    # Step 4: Delete records from dms table where mutation_id matches\n",
    "    if mutation_ids_to_delete:\n",
    "        dms_delete_query = session.query(DMS).filter(Dms.mutation_id.in_(mutation_ids_to_delete)).delete(synchronize_session=False)\n",
    "        print(f\"{dms_delete_query} records deleted from dms table.\")\n",
    "\n",
    "    # Step 5: Delete records from mutation table\n",
    "    mutation_delete_query = session.query(Mutation).filter(Mutation.gene_urn_id.in_(gene_urn_ids_to_delete_1)).delete(synchronize_session=False)\n",
    "    print(f\"{mutation_delete_query} records deleted from mutation table.\")\n",
    "\n",
    "    # Step 6: Commit the changes\n",
    "    session.commit()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    session.rollback()  # Rollback the transaction in case of error\n",
    "\n",
    "finally:\n",
    "    # Close the session\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df5b0c-c1b9-4387-ac31-0eb5406a9757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
