{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c10f462-d372-467e-879a-acbb416a5112",
   "metadata": {},
   "source": [
    "## Process dms data aggregation\n",
    "This notebook is for processing dms data aggregation from MaveDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8815279f-a83b-4f47-a039-40410e05cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import logging\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from Bio.Align import substitution_matrices\n",
    "from Bio import AlignIO\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a8a3505-f09a-4af9-81ee-ddc5a608c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging function\n",
    "def setup_logging(function_name):\n",
    "    log_dir = 'logs'\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_file = os.path.join(log_dir, f'{function_name}.log')\n",
    "\n",
    "    logging.basicConfig(\n",
    "        filename=log_file,\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3584b9ab-4d0f-4b26-a27e-4d57c72bf8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONNECT to the database\n",
    "conn = sqlite3.connect('compar_gen_aggregated_data.db')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac85117c-7048-46ae-9077-09f7f2434f77",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "focus of this analysis is amino acid substitutions compared with substitution scores from matrices like BLOSUM62, PAM250 ...\n",
    "#### Datasets inclusion criteria\n",
    "If csv scoreset from MaveDB does not meet all of the following criteria, it's excluded\n",
    "| Inclusion criteria | Reason |\n",
    "| ------------------ | --------------- |\n",
    "| hgvs_pro value is not 'NA', i.e SNP | SNPs represent changes at the DNA level (single nucleotide changes), which do not always lead to a change in the amino acid sequence. Including SNPs that don't result in amino acid changes would introduce noise into your analysis, as these would not be relevant for a comparison with amino acid substitution scores. |\n",
    "| mutation type = substitution, synonimous, nonsense | Substitution matrices like BLOSUM62 are designed to evaluate the evolutionary likelihood and functional impact of amino acid substitutions. Other types of mutations (e.g., insertions, deletions, frameshifts) alter the protein in different ways and are not comparable to simple substitutions. Including non-substitution mutations in the analysis would lead to mismatched comparisons, as the matrices do not provide relevant scores for these types of mutations. |\n",
    "| single mutant | Double or multiple mutants introduce combinatorial effects that are more complex and not directly comparable to the single substitution scores in BLOSUM62. Including multiple mutants would complicate the analysis and make it difficult to draw clear conclusions about the relationship between DMS scores and BLOSUM62 scores. |\n",
    "| species=Homo sapience | The lack of sufficient data for non-human species in MaveDB, particularly vertebrates, means that any comparative analysis might be statistically underpowered or biased. When more data becomes available, the analysis will be more credible. |\n",
    "| 'score' in dms file is not empty |  |\n",
    "| 'position' in dms file is not empty |  |\n",
    "| unique amino acid mutation | exclude redundant nucleotide mutations that result in the same amino acid change. E.g., c.178_180delinsTAG and c.178_180delinsTAA (in the score set urn:mavedb:00000001-b-2) lead to the same amino acid change, p.Asn60Ter, the scores in these cases are the same, i.e. duplicates |\n",
    "\n",
    "#### Data pre-processing\n",
    "csv files with dms scores downloaded from MaveDB https://zenodo.org/records/11201737 need to be pre-processed before propagating data from them to msa-dms-db database. \n",
    "1. Data in this notebook has been already processed with workflow in Galaxy https://usegalaxy.eu/u/polina/w/dms-aggregated-parse-hgvs-extract-positions\n",
    "   1. parse hgvs_pro to position, ancestral_residue, variant_residue\n",
    "   2. join parsed table with original table from mavedb by hgvs_pro column\n",
    "\n",
    "3. Convert three-code amino acid to one-code (preprocess_all_csvs_convert_3to1letter)\n",
    "\n",
    "#### Data processing\n",
    "1. Populate data to compar_gen_aggregated_data.db (fill_tables_with_all_dms_csv_in_folder)\n",
    "   1. gene and species are fetched from MaveDB API https://api.mavedb.org/api/v1/score-sets/{urn_mavedb} and populated to db\n",
    "    - Challenges: requires more computational and memory resources (applied for VM with more resources)\n",
    "1. Calculate minmax scaled dms scores and fill in db (calculate_minmax_scaled_scores)\n",
    "    - Challenges: currently produces duplicates, need to debug\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d586d-b500-4f3e-a525-bb60457c82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS \n",
    "# Data preprocessing (before filling tables)\n",
    "\n",
    "# Define the dictionary to map three-letter to one-letter amino acid codes\n",
    "AA_CODES: Dict[str, str] = {\n",
    "    \"Ala\": \"A\",  # Alanine\n",
    "    \"Arg\": \"R\",  # Arginine\n",
    "    \"Asn\": \"N\",  # Asparagine\n",
    "    \"Asp\": \"D\",  # Aspartic acid (Aspartate)\n",
    "    \"Cys\": \"C\",  # Cysteine\n",
    "    \"Gln\": \"Q\",  # Glutamine\n",
    "    \"Glu\": \"E\",  # Glutamic acid (Glutamate)\n",
    "    \"Gly\": \"G\",  # Glycine\n",
    "    \"His\": \"H\",  # Histidine\n",
    "    \"Ile\": \"I\",  # Isoleucine\n",
    "    \"Leu\": \"L\",  # Leucine\n",
    "    \"Lys\": \"K\",  # Lysine\n",
    "    \"Met\": \"M\",  # Methionine\n",
    "    \"Phe\": \"F\",  # Phenylalanine\n",
    "    \"Pro\": \"P\",  # Proline\n",
    "    \"Ser\": \"S\",  # Serine\n",
    "    \"Thr\": \"T\",  # Threonine\n",
    "    \"Trp\": \"W\",  # Tryptophan\n",
    "    \"Tyr\": \"Y\",  # Tyrosine\n",
    "    \"Val\": \"V\",  # Valine\n",
    "    \"Ter\": \"*\",  # Termination codon\n",
    "}\n",
    "\n",
    "\n",
    "def preprocess_csv_convert_3to1letter(file_path: str, output_folder: str):\n",
    "    \"\"\"Process a single CSV file to map amino acid codes from three-letter to one-letter notation \n",
    "    creates an output file with extra columns: 'wt_1letter' in output file corresponds to 'ancestral' in input file,\n",
    "    while 'variant_1letter' in output corresponds to 'variant' in input\n",
    "    and save the output.\"\"\"\n",
    "    try:\n",
    "        # Read the CSV file with low_memory=False to avoid DtypeWarning\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "        # Map three-letter codes to one-letter codes for ancestral\n",
    "        df['wt_1letter'] = df['ancestral'].map(AA_CODES)\n",
    "\n",
    "        # Map three-letter codes to one-letter codes for variant\n",
    "        df['variant_1letter'] = df['variant'].map(AA_CODES)\n",
    "\n",
    "        # If variant is '0', replace it with the one-letter code from ancestral\n",
    "        df['variant_1letter'] = df.apply(\n",
    "            lambda row: row['wt_1letter'] if row['variant'] == '0' else row['variant_1letter'], axis=1)\n",
    "\n",
    "        # Save the processed CSV\n",
    "        output_file = os.path.join(output_folder, os.path.basename(file_path))\n",
    "        df.to_csv(output_file, index=False)\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Print the file name and the error message if an exception occurs\n",
    "        print(f\"Issue occurred with file: {file_path}. Error: {str(e)}\")\n",
    "\n",
    "def preprocess_all_csvs_convert_3to1letter(input_folder: str, output_folder: str):\n",
    "    \"\"\"Process all CSV files with preprocess_csv_convert_3to1letter in the input folder and save them to the output folder.\"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Process each CSV file in the input folder\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(input_folder, file_name)\n",
    "            preprocess_csv_convert_3to1letter(file_path, output_folder)\n",
    "\n",
    "    print(\"Processing completed.\")\n",
    "\n",
    "def move_preprocessed_files(all_in, preprocessed_out, preprocessed_in):\n",
    "    \"\"\"Helping function.\n",
    "    Checks which files were processed with process_all_scvs and moves all \n",
    "    processed to folder 'preprocessed_in' from 'all_in'.\"\"\"\n",
    "    # Ensure the output directories exist\n",
    "    os.makedirs(preprocessed_in, exist_ok=True)\n",
    "\n",
    "    # Get the list of files in all_in and preprocessed_out\n",
    "    all_in_files = set(os.listdir(all_in))\n",
    "    preprocessed_out_files = set(os.listdir(preprocessed_out))\n",
    "\n",
    "    # Find common files between all_in and preprocessed_out\n",
    "    common_files = all_in_files.intersection(preprocessed_out_files)\n",
    "\n",
    "    # Move common files from all_in to preprocessed_in\n",
    "    for file_name in common_files:\n",
    "        source_path = os.path.join(all_in, file_name)\n",
    "        destination_path = os.path.join(preprocessed_in, file_name)\n",
    "        shutil.move(source_path, destination_path)\n",
    "        #print(f\"Moved: {file_name} from {all_in} to {preprocessed_in}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a38d7b9-a631-445e-b0b7-387e860931cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_all_csvs_convert_3to1letter('data/mavedb-scores', 'data/mavedb-scores-1letter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3ad8a-7b9f-4384-a912-41109a12130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_preprocessed_files('data/mavedb-scores', 'data/mavedb-scores-1letter', 'data/mavedb-scores-preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c21c9f9b-49bb-4e4b-8d6b-03c29cda7d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get target gene and organism name from MAVEdb\n",
    "def get_target_gene_and_organism(urn_mavedb):\n",
    "    api_url = f\"https://api.mavedb.org/api/v1/score-sets/{urn_mavedb}\"\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        target_gene = data['targetGenes'][0]['name']\n",
    "        target_organism_name = data['targetGenes'][0]['targetSequence']['taxonomy']['organismName']\n",
    "        return target_gene, target_organism_name\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error fetching data from API for URN {urn_mavedb}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to fill tables with aggregated DMS data\n",
    "def fill_tables_with_dms_csv(file_path, urn_mavedb, target_gene, target_organism_name):\n",
    "    setup_logging('fill_tables_with_dms_csv')\n",
    "\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        \n",
    "        for row in reader:\n",
    "            if row['type'] not in ['substitution', 'synonymous']:\n",
    "                logging.info(f\"Skipping row due to 'type': {row['type']}\")\n",
    "                continue\n",
    "\n",
    "            if row['hgvs_pro'].startswith('p.['):\n",
    "                logging.info(f\"Skipping row due to 'hgvs_pro': {row['hgvs_pro']}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                score = float(row['score']) if row['score'].strip() else None\n",
    "            except ValueError as e:\n",
    "                logging.error(f\"Error converting score to float for row: {row}. Error: {e}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                start = int(row['start'])\n",
    "            except ValueError as e:\n",
    "                logging.error(f\"Error converting start to int for row: {row}. Error: {e}\")\n",
    "                continue\n",
    "            \n",
    "            wt_1letter = row['wt_1letter']\n",
    "            variant_1letter = row['variant_1letter']\n",
    "\n",
    "            # Insert gene into Gene table with URN\n",
    "            cursor.execute('SELECT gene_id FROM Gene WHERE gene_name = ?', (target_gene,))\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                gene_id = result[0]\n",
    "                cursor.execute('UPDATE Gene SET urn_mavedb = ? WHERE gene_id = ?', (urn_mavedb, gene_id))\n",
    "            else:\n",
    "                cursor.execute('INSERT INTO Gene (gene_name, urn_mavedb) VALUES (?, ?)', (target_gene, urn_mavedb))\n",
    "                gene_id = cursor.lastrowid\n",
    "\n",
    "            # Insert species into Species table\n",
    "            cursor.execute('SELECT species_id FROM Species WHERE species_name = ?', (target_organism_name,))\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                species_id = result[0]\n",
    "            else:\n",
    "                cursor.execute('INSERT INTO Species (species_name) VALUES (?)', (target_organism_name,))\n",
    "                species_id = cursor.lastrowid\n",
    "\n",
    "            # Check if the mutation already exists in the Mutation table\n",
    "            cursor.execute('''\n",
    "                SELECT mutation_id FROM Mutation \n",
    "                WHERE gene_id = ? AND species_id = ? AND position = ? AND ancestral_residue = ? AND variant_residue = ?\n",
    "            ''', (gene_id, species_id, start, wt_1letter, variant_1letter))\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                mutation_id = result[0]\n",
    "            else:\n",
    "                cursor.execute('''\n",
    "                    INSERT INTO Mutation (gene_id, species_id, position, ancestral_residue, variant_residue)\n",
    "                    VALUES (?, ?, ?, ?, ?)\n",
    "                ''', (gene_id, species_id, start, wt_1letter, variant_1letter))\n",
    "                mutation_id = cursor.lastrowid\n",
    "\n",
    "            # Insert DMS data into the DMS table\n",
    "            if score is not None:\n",
    "                cursor.execute('''\n",
    "                    INSERT INTO DMS (mutation_id, score)\n",
    "                    VALUES (?, ?)\n",
    "                ''', (mutation_id, score))\n",
    "            else:\n",
    "                logging.info(f\"Skipping row with invalid score: {row}\")    \n",
    "    conn.commit()\n",
    "\n",
    "# Function to fill tables with all DMS CSV files in a folder\n",
    "def fill_tables_with_all_dms_csv_in_folder(folder_path):\n",
    "    setup_logging('fill_tables_with_all_dms_csv_in_folder')\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Extract urn_mavedb from the filename\n",
    "            urn_mavedb = filename.replace('csv_urn-mavedb-', 'urn:mavedb:').replace('.scores.csv', '')\n",
    "\n",
    "            # Get target gene and organism name from API\n",
    "            target_gene, target_organism_name = get_target_gene_and_organism(urn_mavedb)\n",
    "            if target_organism_name != 'Homo sapiens':\n",
    "                logging.info(f\"Skipping file due to organism name: {target_organism_name}\")\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            logging.info(f\"Processing file: {file_path} with target_gene: {target_gene}\")\n",
    "            fill_tables_with_dms_csv(file_path, urn_mavedb, target_gene, target_organism_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d72e1a3-35fc-4f87-8fa8-c0f7522b3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process all files in the folder\n",
    "fill_tables_with_all_dms_csv_in_folder('data/batches/batch13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d895b5c-5769-4d98-801b-b60f3da7ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script is producing duplicated, fix it\n",
    "#FUNC\n",
    "#use calculate_minmax_scaled_scores with species_name='Homo sapiens' for aggregated datasets\n",
    "\n",
    "def calculate_minmax_scaled_scores(table_name, score_field, species_name=None, neutral_data_point=0):\n",
    "    setup_logging('calculate_minmax_scaled_scores')\n",
    "    logging.info(f\"Processing table: {table_name} with species_name: {species_name} and neutral_data_point: {neutral_data_point}\")\n",
    "    # Extract data from the specified table\n",
    "    if table_name == 'DMS':\n",
    "        query = '''\n",
    "            SELECT M.gene_id, M.mutation_id, D.{score_field}\n",
    "            FROM DMS D\n",
    "            JOIN Mutation M ON D.mutation_id = M.mutation_id\n",
    "            JOIN Gene G ON M.gene_id = G.gene_id\n",
    "            JOIN Species S ON M.species_id = S.species_id\n",
    "            WHERE S.species_name = ?\n",
    "        '''\n",
    "        query = query.format(score_field=score_field)\n",
    "        df = pd.read_sql_query(query, conn, params=(species_name,))\n",
    "        #print(\"DMS DataFrame Extracted:\\n\", df.head())  # Debugging print statement\n",
    "\n",
    "    elif table_name == 'SubstitutionMatrices':\n",
    "        query = f'''\n",
    "            SELECT amino_acid_x, amino_acid_y, {score_field}\n",
    "            FROM SubstitutionMatrices\n",
    "            WHERE amino_acid_x != amino_acid_y\n",
    "        '''\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        df['mutation_id'] = ''  # For consistency in processing\n",
    "        #print(\"SubstitutionMatrices DataFrame Extracted:\\n\", df.head())  # Debugging print statement\n",
    "\n",
    "    # Shift the scores by the neutral point\n",
    "    df['shifted_score'] = df[score_field] - neutral_data_point\n",
    "    #print(\"Shifted Scores:\\n\", df[['shifted_score']].head())  # Debugging print statement\n",
    "\n",
    "    # Calculate the min and max of the shifted scores\n",
    "    min_val = df['shifted_score'].min()\n",
    "    max_val = df['shifted_score'].max()\n",
    "    #print(f\"Min Value: {min_val}, Max Value: {max_val}\")  # Debugging print statement\n",
    "    logging.info(f\"Processing table {table_name} completed\")\n",
    "\n",
    "    # Apply custom normalization formula\n",
    "    def custom_normalize(x):\n",
    "        if x > 0:\n",
    "            return x / max_val if max_val != 0 else 0\n",
    "        elif x < 0:\n",
    "            return x / abs(min_val) if min_val != 0 else 0\n",
    "        elif x == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    df[f'{score_field}_minmax_scaled'] = df['shifted_score'].apply(custom_normalize)\n",
    "    #print(\"Scaled Values:\\n\", df[[f'{score_field}_minmax_scaled']].head())  # Debugging print statement\n",
    "\n",
    "    # Update the database with the scaled values\n",
    "    if table_name == 'DMS':\n",
    "        for mutation_id, scaled_value in zip(df['mutation_id'], df[f'{score_field}_minmax_scaled']):\n",
    "            cursor.execute(f'''\n",
    "                UPDATE DMS\n",
    "                SET {score_field}_minmax_scaled = ?\n",
    "                WHERE mutation_id = ?\n",
    "            ''', (scaled_value, mutation_id))\n",
    "    elif table_name == 'SubstitutionMatrices':\n",
    "        for amino_acid_x, amino_acid_y, scaled_value in zip(df['amino_acid_x'], df['amino_acid_y'], df[f'{score_field}_minmax_scaled']):\n",
    "            cursor.execute(f'''\n",
    "                UPDATE SubstitutionMatrices\n",
    "                SET {score_field}_minmax_scaled = ?\n",
    "                WHERE amino_acid_x = ? AND amino_acid_y = ?\n",
    "            ''', (scaled_value, amino_acid_x, amino_acid_y))\n",
    "\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f1d62-385f-4fe2-a834-cbdfc17da119",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_minmax_scaled_scores('DMS', 'score', 'Homo sapiens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efcad197-4b69-41df-88a3-9bf519a08532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eda51c1-ede9-4065-abe1-fdd04b793820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 404 Client Error: Not Found for url: https://api.mavedb.org/api/v1/score-sets/PTEN\n",
      "An error occurred: 404 Client Error: Not Found for url: https://api.mavedb.org/api/v1/score-sets/PAX6%20Homeobox%20domain\n",
      "An error occurred: 404 Client Error: Not Found for url: https://api.mavedb.org/api/v1/score-sets/CYP2C19\n",
      "Gene and species information has been written to genes_and_species.txt.\n"
     ]
    }
   ],
   "source": [
    "#working function to help to understand\n",
    "#Fetch species and genes from mavedb api and write to the file\n",
    "def fetch_genes_and_species(output_file):\n",
    "    # Function to fetch target gene and organism name from the API\n",
    "    def get_target_gene_and_organism(urn):\n",
    "        api_url = f\"https://api.mavedb.org/api/v1/score-sets/{urn}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(api_url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            target_gene = data['targetGenes'][0]['name']\n",
    "            target_organism_name = data['targetGenes'][0]['targetSequence']['taxonomy']['organismName']\n",
    "            \n",
    "            return target_gene, target_organism_name\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None, None\n",
    "\n",
    "\n",
    "    # Fetch the urn_mavedb values from the Gene table\n",
    "    cursor.execute(\"SELECT gene_name FROM Gene\")\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Open the output file for writing\n",
    "    with open(output_file, 'w') as file:\n",
    "        # Iterate through the rows and fetch genes and species\n",
    "        for row in rows:\n",
    "            urn = row[0]\n",
    "            target_gene, target_organism_name = get_target_gene_and_organism(urn)\n",
    "            \n",
    "            if target_gene and target_organism_name:\n",
    "                # Write the gene and species to the file\n",
    "                file.write(f\"URN: {urn}\\n\")\n",
    "                file.write(f\"Gene: {target_gene}\\n\")\n",
    "                file.write(f\"Species: {target_organism_name}\\n\")\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Gene and species information has been written to {output_file}.\")\n",
    "\n",
    "# Example usage\n",
    "output_file = 'genes_and_species.txt'\n",
    "fetch_genes_and_species(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1dee2-b7f0-473f-984f-a5e1f4f507a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
